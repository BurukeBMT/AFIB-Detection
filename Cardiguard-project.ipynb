{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c515c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: data/train/aspirin/aspirin_0_0.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_1.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_2.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_3.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_0_4.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_5.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_6.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_7.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_8.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_9.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_0.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_1.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_2.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_3.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_4.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_1_5.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_6.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_7.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_1_8.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_1_9.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_2_0.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_1.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_2.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_3.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_4.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_5.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_6.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_7.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_2_8.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_2_9.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_0_0.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_1.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_2.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_3.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_0_4.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_0_5.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_6.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_7.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_8.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_9.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_0.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_1.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_1_2.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_3.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_4.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_5.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_6.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_7.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_8.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_9.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_0.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_1.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_2_2.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_2_3.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_2_4.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_2_5.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_6.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_7.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_2_8.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_9.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_0.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_1.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_2.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_3.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_4.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_5.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_6.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_7.jpg\n",
      "Downloaded: data/val/unknown/unknown_0_8.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_9.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_0.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_1.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_2.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_3.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_4.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_5.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_6.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_7.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_8.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_9.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_0.jpg\n",
      "Downloaded: data/val/unknown/unknown_2_1.jpg\n",
      "Downloaded: data/val/unknown/unknown_2_2.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_3.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_4.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_5.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_6.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_7.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_8.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_9.jpg\n",
      "\n",
      "ğŸ‰ Dataset downloaded successfully! You can now train the model.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 â€” Dataset Download & Folder Setup\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# ------------- VERIFIED WORKING DATA URLs -------------\n",
    "# These URLs are stable, open-license, and accessible\n",
    "classes = {\n",
    "    \"aspirin\": [\n",
    "        \"https://images.pexels.com/photos/3683056/pexels-photo-3683056.jpeg\",\n",
    "        \"https://images.pexels.com/photos/3683088/pexels-photo-3683088.jpeg\",\n",
    "        \"https://images.pexels.com/photos/4210610/pexels-photo-4210610.jpeg\"\n",
    "    ],\n",
    "    \"warfarin\": [\n",
    "        \"https://images.pexels.com/photos/159211/headache-pain-pills-medication-159211.jpeg\",\n",
    "        \"https://images.pexels.com/photos/360622/pexels-photo-360622.jpeg\",\n",
    "        \"https://images.pexels.com/photos/356040/pexels-photo-356040.jpeg\"\n",
    "    ],\n",
    "    \"unknown\": [\n",
    "        \"https://images.pexels.com/photos/208518/pexels-photo-208518.jpeg\",\n",
    "        \"https://images.pexels.com/photos/593451/pexels-photo-593451.jpeg\",\n",
    "        \"https://images.pexels.com/photos/360622/pexels-photo-360622.jpeg\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Number of duplicates per image (makes dataset larger)\n",
    "COPIES = 10   # Creates about 30 images per class\n",
    "\n",
    "# ------------- CREATE FOLDER STRUCTURE -------------\n",
    "\n",
    "root = Path(\"data\")\n",
    "(train := root / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "(val := root / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create folders for each class\n",
    "for cls in classes:\n",
    "    (train / cls).mkdir(parents=True, exist_ok=True)\n",
    "    (val / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------- DOWNLOAD FUNCTION -------------\n",
    "\n",
    "def download_image(url, save_path):\n",
    "    \"\"\"Download image with browser-like headers to avoid 403 errors\"\"\"\n",
    "    try:\n",
    "        req = urllib.request.Request(\n",
    "            url,\n",
    "            headers={\"User-Agent\": \"Mozilla/5.0\"}  # Spoofs a browser request\n",
    "        )\n",
    "        with urllib.request.urlopen(req) as resp:\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                f.write(resp.read())\n",
    "        print(f\"Downloaded: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {url} -> {e}\")\n",
    "\n",
    "# ------------- DOWNLOAD ALL IMAGES -------------\n",
    "\n",
    "for cls, urls in classes.items():\n",
    "    for i, url in enumerate(urls):\n",
    "        for c in range(COPIES):\n",
    "            fname = f\"{cls}_{i}_{c}.jpg\"\n",
    "            save_dir = train / cls if random.random() > 0.2 else val / cls   # 80/20 split\n",
    "            save_path = save_dir / fname\n",
    "            download_image(url, save_path)\n",
    "\n",
    "print(\"\\nğŸ‰ Dataset downloaded successfully! You can now train the model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92e1f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports & config\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import threading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import cv2\n",
    "import schedule\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "EMAIL_USER = os.getenv(\"EMAIL_USER\")\n",
    "EMAIL_PASS = os.getenv(\"EMAIL_PASS\")\n",
    "CAREGIVER_EMAIL = os.getenv(\"CAREGIVER_EMAIL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1513b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 images belonging to 3 classes.\n",
      "Found 48 images belonging to 3 classes.\n",
      "ğŸ“Œ Classes detected: {'aspirin': 0, 'unknown': 1, 'warfarin': 2}\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 3 â€” Data Generators (Improved)\n",
    "# ============================================\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")  # expect data/train and data/val inside\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH = 16\n",
    "\n",
    "train_dir = str(DATA_DIR / \"train\")\n",
    "val_dir = str(DATA_DIR / \"val\")\n",
    "\n",
    "# Safety check\n",
    "assert (DATA_DIR / \"train\").exists(), \"âŒ Train folder not found. Run Cell 2 first!\"\n",
    "assert (DATA_DIR / \"val\").exists(), \"âŒ Val folder not found. Run Cell 2 first!\"\n",
    "\n",
    "# Training generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation generator (no augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,        # IMPORTANT\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Display class mapping\n",
    "class_indices = train_gen.class_indices\n",
    "print(\"ğŸ“Œ Classes detected:\", class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0451b52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_1.00_224            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_1.00_224            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m163,968\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m387\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,339</span> (9.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,339\u001b[0m (9.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,355</span> (642.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,355\u001b[0m (642.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ” Model is ready for training!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4 â€” MobileNetV2 Model (Improved)\n",
    "# ============================================\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load pretrained MobileNetV2\n",
    "base = MobileNetV2(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze base layers (initial training)\n",
    "base.trainable = False\n",
    "\n",
    "# Build model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=IMG_SIZE + (3,)),\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(len(class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print(\"\\nâœ” Model is ready for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df756f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 10s/step - accuracy: 0.5556 - loss: 0.9427 - val_accuracy: 0.7708 - val_loss: 0.7422\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 7s/step - accuracy: 0.7333 - loss: 0.7226 - val_accuracy: 0.9167 - val_loss: 0.5704\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6s/step - accuracy: 0.7778 - loss: 0.5794 - val_accuracy: 0.9167 - val_loss: 0.4334\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.7778 - loss: 0.5380 - val_accuracy: 0.9167 - val_loss: 0.3506\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8s/step - accuracy: 0.8889 - loss: 0.3950 - val_accuracy: 0.9167 - val_loss: 0.2958\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6s/step - accuracy: 0.9000 - loss: 0.3938 - val_accuracy: 0.9167 - val_loss: 0.2622\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8s/step - accuracy: 0.8556 - loss: 0.3917 - val_accuracy: 0.9167 - val_loss: 0.2344\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7s/step - accuracy: 0.8667 - loss: 0.3403 - val_accuracy: 0.9167 - val_loss: 0.2174\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7s/step - accuracy: 0.8667 - loss: 0.3167 - val_accuracy: 0.9167 - val_loss: 0.2064\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6s/step - accuracy: 0.9111 - loss: 0.2502 - val_accuracy: 0.9167 - val_loss: 0.1981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /home/buruk-bmt/Desktop/Machine Learning/Projects/AFIB-Detection/pill_classifier_mobilenetv2_ft.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: train\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen\n",
    ")\n",
    "\n",
    "# --- Auto-detect save path ---\n",
    "current_dir = os.getcwd()              # Where the notebook is running\n",
    "model_path = os.path.join(current_dir, \"pill_classifier_mobilenetv2_ft.h5\")\n",
    "\n",
    "# --- Save the model ---\n",
    "model.save(model_path)\n",
    "print(f\"Model saved at: {model_path}\")\n",
    "\n",
    "# --- Load the model safely ---\n",
    "if os.path.exists(model_path):\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    print(\"ERROR: Model file not found:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b083d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning setup\n",
    "\n",
    "# Unfreeze base model for fine-tuning\n",
    "base.trainable = True\n",
    "\n",
    "# Freeze first 100 layers (stabilizes training)\n",
    "for layer in base.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile with smaller learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(train_gen, epochs=5, validation_data=val_gen)\n",
    "\n",
    "model.save(\"pill_classifier_mobilenetv2_ft.h5\")\n",
    "\n",
    "model.summary()\n",
    "print(\"Fine-tuning enabled. Ready to train further.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b406dc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'pill_classifier_mobilenetv2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m img_to_array\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpill_classifier_mobilenetv2.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or ft model\u001b[39;00m\n\u001b[32m      7\u001b[39m inv_class_map = {v:k \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m class_indices.items()}\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_image\u001b[39m(img_bgr):\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# img_bgr: numpy array BGR (OpenCV)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Projects/AFIB-Detection/venv/lib/python3.13/site-packages/keras/src/saving/saving_api.py:196\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib.load_model(\n\u001b[32m    190\u001b[39m         filepath,\n\u001b[32m    191\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    193\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Projects/AFIB-Detection/venv/lib/python3.13/site-packages/keras/src/legacy/saving/legacy_h5_format.py:118\u001b[39m, in \u001b[36mload_model_from_hdf5\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    116\u001b[39m opened_new_file = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py.File)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     f = \u001b[43mh5py\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    120\u001b[39m     f = filepath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Projects/AFIB-Detection/venv/lib/python3.13/site-packages/h5py/_hl/files.py:566\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, track_times, **kwds)\u001b[39m\n\u001b[32m    557\u001b[39m     fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[32m    558\u001b[39m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[32m    559\u001b[39m                      alignment_threshold=alignment_threshold,\n\u001b[32m    560\u001b[39m                      alignment_interval=alignment_interval,\n\u001b[32m    561\u001b[39m                      meta_block_size=meta_block_size,\n\u001b[32m    562\u001b[39m                      **kwds)\n\u001b[32m    563\u001b[39m     fcpl = make_fcpl(track_order=track_order, track_times=track_times,\n\u001b[32m    564\u001b[39m                      fs_strategy=fs_strategy, fs_persist=fs_persist,\n\u001b[32m    565\u001b[39m                      fs_threshold=fs_threshold, fs_page_size=fs_page_size)\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     fid = \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    569\u001b[39m     \u001b[38;5;28mself\u001b[39m._libver = libver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Projects/AFIB-Detection/venv/lib/python3.13/site-packages/h5py/_hl/files.py:241\u001b[39m, in \u001b[36mmake_fid\u001b[39m\u001b[34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[39m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[32m    240\u001b[39m         flags |= h5f.ACC_SWMR_READ\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     fid = \u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    243\u001b[39m     fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5f.pyx:104\u001b[39m, in \u001b[36mh5py.h5f.open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'pill_classifier_mobilenetv2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "model = load_model(\"pill_classifier_mobilenetv2_ft.h5\")  # or ft model\n",
    "\n",
    "inv_class_map = {v:k for k,v in class_indices.items()}\n",
    "\n",
    "def predict_image(img_bgr):\n",
    "    # img_bgr: numpy array BGR (OpenCV)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, IMG_SIZE)\n",
    "    x = img_resized.astype(\"float32\") / 255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)\n",
    "    idx = np.argmax(preds[0])\n",
    "    conf = preds[0][idx]\n",
    "    label = inv_class_map[idx]\n",
    "    return label, float(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: webcam scanner (press 'q' to quit)\n",
    "def run_scanner(threshold=0.7, display=True):\n",
    "    cap = cv2.VideoCapture(0)  # 0 = default webcam\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open webcam\")\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            label, conf = predict_image(frame)\n",
    "            text = f\"{label} ({conf:.2f})\"\n",
    "            if display:\n",
    "                cv2.putText(frame, text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow(\"Pill Scanner\", frame)\n",
    "            # decide detection event\n",
    "            if conf >= threshold:\n",
    "                print(\"Detected:\", text)\n",
    "                # You can return or call handler here\n",
    "                # For demo: break when detection occurs\n",
    "                # break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# To run:\n",
    "# run_scanner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: reminders + local notification (console)\n",
    "import schedule\n",
    "import threading\n",
    "import time\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "reminders = [\n",
    "    {\"time\": \"14:30\", \"pill\": \"warfarin\"},\n",
    "    {\"time\": \"20:00\", \"pill\": \"aspirin\"}\n",
    "]\n",
    "\n",
    "def reminder_job(pill_name):\n",
    "    print(f\"[Reminder] Time to take: {pill_name} â€” open scanner to confirm.\")\n",
    "    # Optionally pop a GUI alert (not shown here), or beep\n",
    "    # Start scanner and wait for confirmation for N seconds\n",
    "    confirmed = scanner_confirm(pill_name, timeout=30)  # returns True/False\n",
    "    if not confirmed:\n",
    "        send_caregiver_email(pill_name)\n",
    "\n",
    "def scanner_confirm(expected_pill, timeout=30):\n",
    "    \"\"\"Run scanner for timeout seconds, return True if expected_pill detected.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    start = time.time()\n",
    "    try:\n",
    "        while time.time() - start < timeout:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            label, conf = predict_image(frame)\n",
    "            if label == expected_pill and conf > 0.75:\n",
    "                print(\"Patient confirmed took pill:\", label)\n",
    "                return True\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    print(\"No confirmation within timeout.\")\n",
    "    return False\n",
    "\n",
    "# schedule these\n",
    "for r in reminders:\n",
    "    schedule.every().day.at(r[\"time\"]).do(reminder_job, pill_name=r[\"pill\"])\n",
    "\n",
    "# run scheduler in background thread\n",
    "def run_schedule_loop():\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)\n",
    "\n",
    "thread = threading.Thread(target=run_schedule_loop, daemon=True)\n",
    "thread.start()\n",
    "print(\"Reminder scheduler running in background.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac81db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: email notifier\n",
    "def send_caregiver_email(pill_name):\n",
    "    if not EMAIL_USER or not EMAIL_PASS or not CAREGIVER_EMAIL:\n",
    "        print(\"Email credentials not configured.\")\n",
    "        return\n",
    "    msg = EmailMessage()\n",
    "    msg['Subject'] = f\"CardiaGuard: Missed medication - {pill_name}\"\n",
    "    msg['From'] = EMAIL_USER\n",
    "    msg['To'] = CAREGIVER_EMAIL\n",
    "    body = f\"Patient missed scheduled dose of {pill_name}. No confirmation from scanner.\"\n",
    "    msg.set_content(body)\n",
    "    # optional: attach last detected image or timestamp\n",
    "    try:\n",
    "        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "        server.login(EMAIL_USER, EMAIL_PASS)\n",
    "        server.send_message(msg)\n",
    "        server.quit()\n",
    "        print(\"Caregiver notified by email.\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to send email:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
