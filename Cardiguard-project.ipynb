{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e1f8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 04:15:28.657174: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-16 04:15:31.179197: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-16 04:15:35.129416: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: imports & config\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import threading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import cv2\n",
    "import schedule\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "EMAIL_USER = os.getenv(\"EMAIL_USER\")\n",
    "EMAIL_PASS = os.getenv(\"EMAIL_PASS\")\n",
    "CAREGIVER_EMAIL = os.getenv(\"CAREGIVER_EMAIL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c515c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: data/train/aspirin/aspirin_0_0.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_1.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_2.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_3.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_4.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_5.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_6.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_0_7.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_8.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_0_9.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_0.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_1.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_2.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_3.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_1_4.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_5.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_6.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_7.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_8.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_1_9.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_2_0.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_1.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_2.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_3.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_4.jpg\n",
      "Downloaded: data/val/aspirin/aspirin_2_5.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_6.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_7.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_8.jpg\n",
      "Downloaded: data/train/aspirin/aspirin_2_9.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_0.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_1.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_2.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_3.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_4.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_5.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_0_6.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_0_7.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_8.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_0_9.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_0.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_1.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_2.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_1_3.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_4.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_5.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_6.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_7.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_8.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_1_9.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_0.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_1.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_2_2.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_3.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_4.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_5.jpg\n",
      "Downloaded: data/val/warfarin/warfarin_2_6.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_7.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_8.jpg\n",
      "Downloaded: data/train/warfarin/warfarin_2_9.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_0.jpg\n",
      "Downloaded: data/val/unknown/unknown_0_1.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_2.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_3.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_4.jpg\n",
      "Downloaded: data/val/unknown/unknown_0_5.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_6.jpg\n",
      "Downloaded: data/val/unknown/unknown_0_7.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_8.jpg\n",
      "Downloaded: data/train/unknown/unknown_0_9.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_0.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_1.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_2.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_3.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_4.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_5.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_6.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_7.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_8.jpg\n",
      "Downloaded: data/train/unknown/unknown_1_9.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_0.jpg\n",
      "Downloaded: data/val/unknown/unknown_2_1.jpg\n",
      "Downloaded: data/val/unknown/unknown_2_2.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_3.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_4.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_5.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_6.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_7.jpg\n",
      "Downloaded: data/train/unknown/unknown_2_8.jpg\n",
      "Downloaded: data/val/unknown/unknown_2_9.jpg\n",
      "\n",
      "ðŸŽ‰ Dataset downloaded successfully! You can now train the model.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 â€” Dataset Download & Folder Setup\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# ------------- VERIFIED WORKING DATA URLs -------------\n",
    "# These URLs are stable, open-license, and accessible\n",
    "classes = {\n",
    "    \"aspirin\": [\n",
    "        \"https://images.pexels.com/photos/3683056/pexels-photo-3683056.jpeg\",\n",
    "        \"https://images.pexels.com/photos/3683088/pexels-photo-3683088.jpeg\",\n",
    "        \"https://images.pexels.com/photos/4210610/pexels-photo-4210610.jpeg\"\n",
    "    ],\n",
    "    \"warfarin\": [\n",
    "        \"https://images.pexels.com/photos/159211/headache-pain-pills-medication-159211.jpeg\",\n",
    "        \"https://images.pexels.com/photos/360622/pexels-photo-360622.jpeg\",\n",
    "        \"https://images.pexels.com/photos/356040/pexels-photo-356040.jpeg\"\n",
    "    ],\n",
    "    \"unknown\": [\n",
    "        \"https://images.pexels.com/photos/208518/pexels-photo-208518.jpeg\",\n",
    "        \"https://images.pexels.com/photos/593451/pexels-photo-593451.jpeg\",\n",
    "        \"https://images.pexels.com/photos/360622/pexels-photo-360622.jpeg\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Number of duplicates per image (makes dataset larger)\n",
    "COPIES = 10   # Creates about 30 images per class\n",
    "\n",
    "# ------------- CREATE FOLDER STRUCTURE -------------\n",
    "\n",
    "root = Path(\"data\")\n",
    "(train := root / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "(val := root / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create folders for each class\n",
    "for cls in classes:\n",
    "    (train / cls).mkdir(parents=True, exist_ok=True)\n",
    "    (val / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------- DOWNLOAD FUNCTION -------------\n",
    "\n",
    "def download_image(url, save_path):\n",
    "    \"\"\"Download image with browser-like headers to avoid 403 errors\"\"\"\n",
    "    try:\n",
    "        req = urllib.request.Request(\n",
    "            url,\n",
    "            headers={\"User-Agent\": \"Mozilla/5.0\"}  # Spoofs a browser request\n",
    "        )\n",
    "        with urllib.request.urlopen(req) as resp:\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                f.write(resp.read())\n",
    "        print(f\"Downloaded: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {url} -> {e}\")\n",
    "\n",
    "# ------------- DOWNLOAD ALL IMAGES -------------\n",
    "\n",
    "for cls, urls in classes.items():\n",
    "    for i, url in enumerate(urls):\n",
    "        for c in range(COPIES):\n",
    "            fname = f\"{cls}_{i}_{c}.jpg\"\n",
    "            save_dir = train / cls if random.random() > 0.2 else val / cls   # 80/20 split\n",
    "            save_path = save_dir / fname\n",
    "            download_image(url, save_path)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Dataset downloaded successfully! You can now train the model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1513b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 3 â€” Data Generators (Improved)\n",
    "# ============================================\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")  # expect data/train and data/val inside\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH = 16\n",
    "\n",
    "train_dir = str(DATA_DIR / \"train\")\n",
    "val_dir = str(DATA_DIR / \"val\")\n",
    "\n",
    "# Safety check\n",
    "assert (DATA_DIR / \"train\").exists(), \"âŒ Train folder not found. Run Cell 2 first!\"\n",
    "assert (DATA_DIR / \"val\").exists(), \"âŒ Val folder not found. Run Cell 2 first!\"\n",
    "\n",
    "# Training generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation generator (no augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,        # IMPORTANT\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Display class mapping\n",
    "class_indices = train_gen.class_indices\n",
    "print(\"ðŸ“Œ Classes detected:\", class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 4 â€” MobileNetV2 Model (Improved)\n",
    "# ============================================\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load pretrained MobileNetV2\n",
    "base = MobileNetV2(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze base layers (initial training)\n",
    "base.trainable = False\n",
    "\n",
    "# Build model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=IMG_SIZE + (3,)),\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(len(class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print(\"\\nâœ” Model is ready for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df756f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: train\n",
    "EPOCHS = 10\n",
    "history = model.fit(train_gen,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=val_gen)\n",
    "\n",
    "# Save model\n",
    "model = load_model(\"pill_classifier_mobilenetv2_ft.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b083d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning setup\n",
    "\n",
    "# Unfreeze base model for fine-tuning\n",
    "base.trainable = True\n",
    "\n",
    "# Freeze first 100 layers (stabilizes training)\n",
    "for layer in base.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile with smaller learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(train_gen, epochs=5, validation_data=val_gen)\n",
    "\n",
    "model.save(\"pill_classifier_mobilenetv2_ft.h5\")\n",
    "\n",
    "model.summary()\n",
    "print(\"Fine-tuning enabled. Ready to train further.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b406dc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'pill_classifier_mobilenetv2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m img_to_array\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpill_classifier_mobilenetv2.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or ft model\u001b[39;00m\n\u001b[32m      7\u001b[39m inv_class_map = {v:k \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m class_indices.items()}\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_image\u001b[39m(img_bgr):\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# img_bgr: numpy array BGR (OpenCV)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Projects/AFIB-Detection/venv/lib/python3.13/site-packages/keras/src/saving/saving_api.py:196\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib.load_model(\n\u001b[32m    190\u001b[39m         filepath,\n\u001b[32m    191\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    193\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Projects/AFIB-Detection/venv/lib/python3.13/site-packages/keras/src/legacy/saving/legacy_h5_format.py:118\u001b[39m, in \u001b[36mload_model_from_hdf5\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    116\u001b[39m opened_new_file = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py.File)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     f = \u001b[43mh5py\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    120\u001b[39m     f = filepath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Projects/AFIB-Detection/venv/lib/python3.13/site-packages/h5py/_hl/files.py:566\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, track_times, **kwds)\u001b[39m\n\u001b[32m    557\u001b[39m     fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[32m    558\u001b[39m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[32m    559\u001b[39m                      alignment_threshold=alignment_threshold,\n\u001b[32m    560\u001b[39m                      alignment_interval=alignment_interval,\n\u001b[32m    561\u001b[39m                      meta_block_size=meta_block_size,\n\u001b[32m    562\u001b[39m                      **kwds)\n\u001b[32m    563\u001b[39m     fcpl = make_fcpl(track_order=track_order, track_times=track_times,\n\u001b[32m    564\u001b[39m                      fs_strategy=fs_strategy, fs_persist=fs_persist,\n\u001b[32m    565\u001b[39m                      fs_threshold=fs_threshold, fs_page_size=fs_page_size)\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     fid = \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    569\u001b[39m     \u001b[38;5;28mself\u001b[39m._libver = libver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Machine Learning/Projects/AFIB-Detection/venv/lib/python3.13/site-packages/h5py/_hl/files.py:241\u001b[39m, in \u001b[36mmake_fid\u001b[39m\u001b[34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[39m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[32m    240\u001b[39m         flags |= h5f.ACC_SWMR_READ\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     fid = \u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    243\u001b[39m     fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5f.pyx:104\u001b[39m, in \u001b[36mh5py.h5f.open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'pill_classifier_mobilenetv2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "model = load_model(\"pill_classifier_mobilenetv2.h5\")  # or ft model\n",
    "\n",
    "inv_class_map = {v:k for k,v in class_indices.items()}\n",
    "\n",
    "def predict_image(img_bgr):\n",
    "    # img_bgr: numpy array BGR (OpenCV)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, IMG_SIZE)\n",
    "    x = img_resized.astype(\"float32\") / 255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)\n",
    "    idx = np.argmax(preds[0])\n",
    "    conf = preds[0][idx]\n",
    "    label = inv_class_map[idx]\n",
    "    return label, float(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: webcam scanner (press 'q' to quit)\n",
    "def run_scanner(threshold=0.7, display=True):\n",
    "    cap = cv2.VideoCapture(0)  # 0 = default webcam\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open webcam\")\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            label, conf = predict_image(frame)\n",
    "            text = f\"{label} ({conf:.2f})\"\n",
    "            if display:\n",
    "                cv2.putText(frame, text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow(\"Pill Scanner\", frame)\n",
    "            # decide detection event\n",
    "            if conf >= threshold:\n",
    "                print(\"Detected:\", text)\n",
    "                # You can return or call handler here\n",
    "                # For demo: break when detection occurs\n",
    "                # break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# To run:\n",
    "# run_scanner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: reminders + local notification (console)\n",
    "import schedule\n",
    "import threading\n",
    "import time\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "\n",
    "reminders = [\n",
    "    {\"time\": \"14:30\", \"pill\": \"warfarin\"},\n",
    "    {\"time\": \"20:00\", \"pill\": \"aspirin\"}\n",
    "]\n",
    "\n",
    "def reminder_job(pill_name):\n",
    "    print(f\"[Reminder] Time to take: {pill_name} â€” open scanner to confirm.\")\n",
    "    # Optionally pop a GUI alert (not shown here), or beep\n",
    "    # Start scanner and wait for confirmation for N seconds\n",
    "    confirmed = scanner_confirm(pill_name, timeout=30)  # returns True/False\n",
    "    if not confirmed:\n",
    "        send_caregiver_email(pill_name)\n",
    "\n",
    "def scanner_confirm(expected_pill, timeout=30):\n",
    "    \"\"\"Run scanner for timeout seconds, return True if expected_pill detected.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    start = time.time()\n",
    "    try:\n",
    "        while time.time() - start < timeout:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            label, conf = predict_image(frame)\n",
    "            if label == expected_pill and conf > 0.75:\n",
    "                print(\"Patient confirmed took pill:\", label)\n",
    "                return True\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    print(\"No confirmation within timeout.\")\n",
    "    return False\n",
    "\n",
    "# schedule these\n",
    "for r in reminders:\n",
    "    schedule.every().day.at(r[\"time\"]).do(reminder_job, pill_name=r[\"pill\"])\n",
    "\n",
    "# run scheduler in background thread\n",
    "def run_schedule_loop():\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)\n",
    "\n",
    "thread = threading.Thread(target=run_schedule_loop, daemon=True)\n",
    "thread.start()\n",
    "print(\"Reminder scheduler running in background.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac81db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: email notifier\n",
    "def send_caregiver_email(pill_name):\n",
    "    if not EMAIL_USER or not EMAIL_PASS or not CAREGIVER_EMAIL:\n",
    "        print(\"Email credentials not configured.\")\n",
    "        return\n",
    "    msg = EmailMessage()\n",
    "    msg['Subject'] = f\"CardiaGuard: Missed medication - {pill_name}\"\n",
    "    msg['From'] = EMAIL_USER\n",
    "    msg['To'] = CAREGIVER_EMAIL\n",
    "    body = f\"Patient missed scheduled dose of {pill_name}. No confirmation from scanner.\"\n",
    "    msg.set_content(body)\n",
    "    # optional: attach last detected image or timestamp\n",
    "    try:\n",
    "        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "        server.login(EMAIL_USER, EMAIL_PASS)\n",
    "        server.send_message(msg)\n",
    "        server.quit()\n",
    "        print(\"Caregiver notified by email.\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to send email:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
